---
title: "Regression model Assessment"
author: "sakinah"
date: "December 27, 2015"
output: word_document
---
In this project, our goal is to use data about personal activity from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: 
http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

## Executive summary

This analysis will help to quantify how well the self movement activity called weight lifting exercises based on the data collected from the device. The total number of predictors are 159 and the there are five classes for the outcome variables.

## Data Getting
The training data : 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
The test data : 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The source of the data is: http://groupware.les.inf.puc-rio.br/har.  

```{r}
library(caret)
library(kernlab)
library(ggplot2)
library(randomForest)
URL1 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URL2 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename1 <- "pml-training.csv"
filename2 <- "pml-testing.csv"
download.file(url=URL1, destfile=filename1,method="curl")
download.file(url=URL2, destfile=filename2,method="curl")
training <- read.csv("pml-training.csv",row.names=1,na.strings = "")
testing <- read.csv("pml-testing.csv",row.names=1,na.strings = "NA")

```

## Data Preprocessing

The model that we going to use is random forest. Therefore the data must be checked for possible missing values. Only column with 70% of the data filled will be used for decision making.
```{r}
valid_columns <- c()
for (i in colnames(training)[-160]) {
  # [-160] Used to exclude last column, "classes"
  if((sum(is.na(training[,i]))/ length(training[,i]) ) < 0.7) {
    if ((sum(is.na(testing[,i])))/ length(testing[,i]) < 0.7) {
      valid_columns <- c(valid_columns, i)
    }
  }
}
valid_columns <- valid_columns[-(1:7)]
data2 <- testing[,c(valid_columns, "classe")]
data <- training[,c(valid_columns, "classe")]
set.seed(2015)
inTrain <- createDataPartition(y = data$classe, p = 0.7, list = FALSE)
training <- data[inTrain,]
validating <- data[-inTrain,]
```

## Prediction Model using Random Forest
Random forest is the most effective model for prediction but it requires significant computational effort.
```{r}
model <- randomForest(classe ~ . , data = training) ; model
model
```

The model give a resonable accurate result based on the confusion matrix.

## Model Evaluation
Step 1: is to look for the varification of variable important measures as produced by random forest model
```{r}
importance(model)
```

Step 2: Evaluate the model by using validating data 

```{r}
colum<-c(valid_columns,"classe")
newdata = testing[,valid_columns]
newd<-c(newdata,"classe")
prediction <- predict(model, newdata = testing[,valid_columns])
print(prediction)
```


# Model Test
```{r}
# pml_write_files = function(x){
#   n = length(x)
#   for(i in 1:n){
#     filename = paste0("problem_id_",i,".txt")
#     write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
#   }
# }
#pml_write_files(prediction)
```
